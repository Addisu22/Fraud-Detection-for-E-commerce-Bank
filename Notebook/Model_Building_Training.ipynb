{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f9e716",
   "metadata": {},
   "source": [
    "# Task 2 - Model Building and Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5952544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install matplolib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd06e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import ipaddress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "sys.path.append(os.path.abspath(\"../Script\"))\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, average_precision_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b3360f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "# print(os.getcwd()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d524537c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: Data/Fraud_Data.csv | Rows: 151112, Columns: 11\n",
      "Cleaned: Removed duplicates and empty rows.\n",
      "Loaded: Data/IpAddress_to_Country.csv | Rows: 138846, Columns: 3\n",
      "Cleaned: Removed duplicates and empty rows.\n",
      "Loaded: Data/creditcard.csv | Rows: 284807, Columns: 31\n",
      "Cleaned: Removed duplicates and empty rows.\n"
     ]
    }
   ],
   "source": [
    "    # Load datasets\n",
    "fraud_df = load_and_clean_data(\"Data/Fraud_Data.csv\")\n",
    "ip_df = load_and_clean_data(\"Data/IpAddress_to_Country.csv\")\n",
    "credit_df = load_and_clean_data(\"Data/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72bde69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_load import *\n",
    "from model_building_training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef6faa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Credit Card Dataset ===\n",
      "\n",
      "Logistic Regression Results:\n",
      "F1-Score: 0.1\n",
      "AUC-PR: 0.0465\n",
      "Confusion Matrix:\n",
      " [[55169  1482]\n",
      " [   12    83]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.99     56651\n",
      "         1.0       0.05      0.87      0.10        95\n",
      "\n",
      "    accuracy                           0.97     56746\n",
      "   macro avg       0.53      0.92      0.54     56746\n",
      "weighted avg       1.00      0.97      0.99     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Credit Card Dataset\n",
    "print(\"=== Credit Card Dataset ===\")\n",
    "X_train, X_test, y_train, y_test = prepare_data(credit_df, 'Class')\n",
    "train_and_evaluate(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6fe430",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_pred, y_test, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.columns = report_df.columns.str.capitalize()\n",
    "report_df.index = report_df.index.str.capitalize()\n",
    "report_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e020cf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fraud Dataset ===\n",
      "\n",
      "Logistic Regression Results:\n",
      "F1-Score: 0.1619\n",
      "AUC-PR: 0.095\n",
      "Confusion Matrix:\n",
      " [[14002 13391]\n",
      " [ 1401  1429]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.51      0.65     27393\n",
      "         1.0       0.10      0.50      0.16      2830\n",
      "\n",
      "    accuracy                           0.51     30223\n",
      "   macro avg       0.50      0.51      0.41     30223\n",
      "weighted avg       0.83      0.51      0.61     30223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fraud Dataset\n",
    "print(\"\\n=== Fraud Dataset ===\")\n",
    "X_train2, X_test2, y_train2, y_test2 = prepare_data(fraud_df, 'class')\n",
    "train_and_evaluate(X_train2, X_test2, y_train2, y_test2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
