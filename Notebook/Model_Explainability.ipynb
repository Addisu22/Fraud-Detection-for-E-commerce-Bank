{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0539b9f6",
   "metadata": {},
   "source": [
    "# Task 3 - Model Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33bf4b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ee5603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import os\n",
    "import sys\n",
    "import ipaddress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "sys.path.append(os.path.abspath(\"../Script\"))\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, average_precision_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4440c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "# print(os.getcwd()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dd61e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_load import *\n",
    "from model_explain import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7daba8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: Data/Fraud_Data.csv | Rows: 151112, Columns: 11\n",
      "Cleaned: Removed duplicates and empty rows.\n",
      "Loaded: Data/IpAddress_to_Country.csv | Rows: 138846, Columns: 3\n",
      "Cleaned: Removed duplicates and empty rows.\n",
      "Loaded: Data/creditcard.csv | Rows: 284807, Columns: 31\n",
      "Cleaned: Removed duplicates and empty rows.\n"
     ]
    }
   ],
   "source": [
    "    # Load datasets\n",
    "fraud_df = load_and_clean_data(\"Data/Fraud_Data.csv\")\n",
    "ip_df = load_and_clean_data(\"Data/IpAddress_to_Country.csv\")\n",
    "credit_df = load_and_clean_data(\"Data/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6ef359",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bal_scaled (numpy or pd.DataFrame) after SMOTE + scaling\n",
    "xgb_model (trained XGBoostClassifier)\n",
    "\n",
    "# Convert back to DataFrame if needed (important for feature names in SHAP)\n",
    "if not isinstance(X_train_bal_scaled, pd.DataFrame):\n",
    "    X_train_df = pd.DataFrame(X_train_bal_scaled, columns=X.columns)\n",
    "else:\n",
    "    X_train_df = X_train_bal_scaled\n",
    "\n",
    "# Interpret model\n",
    "explain_model_with_shap(model=xgb_model, X_train=X_train_df, X_sample=0)\n",
    "Call SHAP interpretation function\n",
    "explain_model_with_shap(best_model, X_train_scaled, X_sample=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
