{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0539b9f6",
   "metadata": {},
   "source": [
    "# Task 3 - Model Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33bf4b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install shap\n",
    "# %pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ee5603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "from sklearn.metrics import f1_score, confusion_matrix, average_precision_score\n",
    "import os\n",
    "import sys\n",
    "import ipaddress\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "sys.path.append(os.path.abspath(\"../Script\"))\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, average_precision_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4440c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "# print(os.getcwd()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dd61e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_load import *\n",
    "from model_explain import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7daba8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: Data/Fraud_Data.csv | Rows: 151112, Columns: 11\n",
      "Cleaned: Removed duplicates and empty rows.\n",
      "Loaded: Data/IpAddress_to_Country.csv | Rows: 138846, Columns: 3\n",
      "Cleaned: Removed duplicates and empty rows.\n",
      "Loaded: Data/creditcard.csv | Rows: 284807, Columns: 31\n",
      "Cleaned: Removed duplicates and empty rows.\n"
     ]
    }
   ],
   "source": [
    "    # Load datasets\n",
    "df = load_and_clean_data(\"Data/Fraud_Data.csv\")\n",
    "ip_df = load_and_clean_data(\"Data/IpAddress_to_Country.csv\")\n",
    "credit_df = load_and_clean_data(\"Data/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6ef359",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bal_scaled (numpy or pd.DataFrame) after SMOTE + scaling\n",
    "xgb_model (trained XGBoostClassifier)\n",
    "\n",
    "# Convert back to DataFrame if needed (important for feature names in SHAP)\n",
    "if not isinstance(X_train_bal_scaled, pd.DataFrame):\n",
    "    X_train_df = pd.DataFrame(X_train_bal_scaled, columns=X.columns)\n",
    "else:\n",
    "    X_train_df = X_train_bal_scaled\n",
    "\n",
    "# Interpret model\n",
    "explain_model_with_shap(model=xgb_model, X_train=X_train_df, X_sample=0)\n",
    "Call SHAP interpretation function\n",
    "explain_model_with_shap(best_model, X_train_scaled, X_sample=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is creditcard dataset and already preprocessed\n",
    "X_train, X_test, y_train, y_test = prepare_data(df, target_col='class')\n",
    "\n",
    "# Optional: scaling + SMOTE\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Train logistic regression\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Evaluate\n",
    "f1_log, auc_log = evaluate_model(log_model, X_test_scaled, y_test, name=\"Logistic Regression\")\n",
    "f1_xgb, auc_xgb = evaluate_model(xgb_model, X_test_scaled, y_test, name=\"XGBoost\")\n",
    "\n",
    "# Choose best model\n",
    "best_model = xgb_model if f1_xgb > f1_log else log_model\n",
    "print(\"\\nBest model selected:\", \"XGBoost\" if best_model == xgb_model else \"Logistic Regression\")\n",
    "\n",
    "# SHAP explanation\n",
    "X_train_df = pd.DataFrame(X_train_bal, columns=X_train.columns)\n",
    "explain_model_with_shap(best_model, X_train_df, X_sample=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
